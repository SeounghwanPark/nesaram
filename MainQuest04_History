히스토리(성환님)  ▶ 프로젝트 진행 및 히스토리 정리위해
**1일차(2/24) :** 팀 빌딩과 데이터 분석

- OT ( 10:10 ~ 10:30 )
- 팀별 아이스브레이킹
- 데이터 분석
    - 파일별 데이터 확인
    - 데이터 상세 내용 확인
    - 데이터셋 간 연계방안 고민
    - 분석 방향 논의(주제 선정)

**역할분배 중요**

코드, 전처리, 분석,머신러닝, 발표준비,

데이터분석 평가 방향

분석하기 전에 가설세우고 - 분석하기

- 가설검증부분에 집중하자(새로운 시도 등)
- 가설이 틀릴때 외 틀린지 분석하고 분석하고
- 발표시 잘한것만 발표 추가 해서 실패한것도 발표 왜 그런지? 에 대한 깊게 들어가는
- 비즈니스 인사이트 도출

**팀 회의 기록로그**

주제 : 본인이 잘하는거 이야기하기(**아이스 브레이킹**) > 역할 분담을 위한 사전 정보공유

프로젝트 진행시 필요한 역할구분

1. 팀장(프로젝트 리더) : 헌수님

2.  데이터 엔지니어 : 
       데이터전처리, 품질검증,분석환경

3. 데이터 분석가 : 
      EDA수행, 통계적분석 및 인사이트 도출

4. 비즈니스 분석가 : 
      데이터관련 트렌드 분석, 비즈니스관점의 인사이트도출, 

역할구분= 주요담당자로 선정하여 다른역할도 같이 할수 있도록 하는것이 주요목적임. 

유빈 - 코딩, 발표자료 작성

상혁 - 대학원 졸업했으며, 발표를 많이 해봤다

헌수 - 하라는건 할수 있다 분위기조성 및 항상 질문자세 되있다

성환 - 전체적 인 서포트 진행, 어느한사람에게만 맡기지 말고  그분이 다른조원에게 시키는식으로 역할을주자

공통적인 작업 공유와 히스토리정리 로 어떤 방식으로 할지

주제 : 코렙, 깃허브 인데 어떤지 이중어떤것으로 할지?

유빈 : 코렙을 사용해 봤는데 깃허브는 사용해보지 못해서

상혁 - 공유는 동의 한다 깃허브, 코렙 상관없다

유빈 - 깃허브 설정보다는 코렙으로 하는게 유용할거 같다.

유빈- 새로운 설정이 필요한 깃허브보다는 코렙선호

성환 - 사용해본 경험이 있는 것으로 팀에 진행상황은 코렙에 작성하고 (각자 피드백하기로)

팀장 선출 (의사소통을 원할히 할수 있는 사람으로)

성환 - 팀장을 하루씩 바꿔가면서 해보자 장점(본인이 팀장을 해본 간접경험습득)보다는 단점이 적어서 괜찮을거 같다

상혁 - 팀장이 혼자서 이끌어 간다고 해도 방향성은 모두가 알고 있어서 팀장을 나눠서 하는것도 대세에는 지상이 없을거 같다.

헌수 - 팀장이 팀원들의견을 듣고 하는거기 때문에 하루씩 해보는것도 좋겠다.

성환 - 진행에 대해 질문 후 ***수정사항*** : (팀장은 한명으로 해야 되고, 리더쉽에 대한 가산점은 추가될 수 있다. 팀장선출로 바로 진행하자)

상혁 - 성환, 헌수님 중에 팀장으로 하는것으로 하는게

유빈 - 동일한 의견으로 성환과 헌수님중에 하는걸로 합시다.

헌수 - 해본적은 없는데 잘할지 모르고 질문이 많을수는 있다.

성환 - 헌수님이 해보시는게 다수결로 의견 나왔고 어떠신지?

팀장 : 김헌수님 으로 결정 : 질문이 많고 항상 Why라는 의구심이 필요하다고 생각하며, 의사소통에 대한 중요성을 감안하여 다수결로 정함.

성환 - 팀명은 테이터 셋을 먼저 정하고 유추되는 것으로 팀명을 정하는것이 어떤가?

예를 들어 일본데이터로 선택했으면 "이번기회에 일본한번가보자" 이런식으로 할수 있으니...

성환- **데이터셋 정하는 과정( 각자 의견 나누고, 다수결로 정하자)**

헌수 - 별5개는 어렵고 중간거 1. 일본 2.구글 플레이 거로

상혁 - 1. 구글 플레이 2. 일본 브라질은 데이터셋이 뭔지 파악부터 해야된다는 느낌이다.

유빈 - 1. 구글, 2. 일본

성환 - 1. 브라질, 2일본  지금까지의 의견으로는 구글, 일본으로 좁혀지는데

성환 - 브라질, 일본 중에서만 하나만 골라서 다시 투표후 다수결로 합시다.

유빈 - 택스트데이터가 잼있을거 같다. 그래서 가설이 제한적인 구글보다는 그래서 일본데이터 선호

상혁 - 전에 텍스트 관련(딜레이관련해본적이 있어서) 데이터를 해본적이 있어서 괜찮을거 같다.

성환 - 별점 중간이 일본이기도 하고 별점이 가장낮은것은 피하고 싶다.

헌수 - 처음부터 일본으로 말했듯이 일본선호.

성환 - 그럼 일본데이터셋을 결정하고 이제 관련 팀 명을 정합시다.

유빈 - 오마카세(다양한 재로로 만든 음식이고 조원이 다양한사람들이 모였으므로)

상혁 - ”헌수님의 오마카세” 팀장의 진행으로 가는 오마카세이므로  했지만 ***오마카세*** 추천

성환 - 헌수님의 오마카세도 괜찮을거 같다.

헌수 - 오마카세가 강렬해서 다른의견은 

유빈 - 우유빛깔 헌수님의 오마카세 보다는  대명사 같이 ”오마카세”

***결론*** - 일본과 관련된 것이기도 하고 최근 흑백요리사의 인기로 최근 트랜드와 더불어 인상이 깊을것 같아  
“**오마카세**”(팀명 의미 : 다양한 식재료들이 서로 상호 융합 보완 상승 효과를 하며 멋진 조화를 이룰때 맛있는 음식이 탄생하듯이 
다양한 조원들의 생각과 경험들이 서로 의논하고 토의하는 과정을 거치며 결과적으로 멋있는 프로젝트를 만들자는 의미.
** 마치 다양한 식재료들이 서로 조화를 이루며 맛있는 요리가 탄생하듯, **각 조원의 생각과 경험이 융합되고 보완되며** 
멋진 프로젝트로 완성되기를 바랍니다. **의논하고 토의하는 과정 속에서 아이디어가 발전하고 시너지를 발휘**하며, 
최상의 결과를 만들어낼 수 있을 것입니다.)  -헌수-

1. 일본 데이터셋 받아서 살펴보기

1-0 데이터셋 받는데 문제있음(인증이 필요하고 개인정보 차원에서 다른시도로 해보느라  시간지체됨)

1-1 진행 중 시간지체

공통 : 유빈님이 받은 데이터를 구글 드라이브 공유한 코렙코드로 다른 조원도 같은 경로로 진행을 해볼려고 했으나,

구글 드라이브에서 경로설정 관련하여 자른 조원에서는 코드실행시 파일경로나 파일이 없다는 애러가 나와서 해결해 볼려고 시도하던중.

성환 : 일단 데이터 파일로 각자 노트북 환경에 경로로해서 실행하는걸로 진행하자고 의견을 냈습니다.

서로 파일의 경로는 다르다는것을 인지하고 있으면 나중에 최종 정리할때 참고할수 있으니 일단 그렇게 시간을 save해서 계속 진행하는걸로 결정합시다.

팀의 정보 공유 : 파일의 경로는 조원들의 개인경로로 설정하여 진행하기로 함.

**2/24 12:50까지의 Main Quest 04 Project 진행 사항**
시간지체가 많이 되었다는 느낌으로 조바심이 들고
조원들끼리 많이 소통하여 문제없이 진행되기를 바람( 다행히 모두 최선을 다하여 문제해결을 찾고 같이 고민하는 분위기여서 긍정적임)

---

→ feedback : 코렙으로 공유해서하는 방법은 해결됨. 유빈님이 구글드라이브에서 개인별로 설정하는 단계를 찾아서 이문제는 해결되었음.

# 데이터 크기 확인

train.tsv : 1482535 rows × 8 columns

test.tsv : 693359 rows × 7 columns

sample_submission.csv : 693359 rows × 1 columns

sample_submission_stg2.csv :3460725 rows × 1 columns

test_stg2.tsv : 3460725 rows × 7 columns

sample_submission_df, sample_submission_stg2_df 비교해보니
동일한 통계량과 결측치로  stg2의 데이터를 사용
**조원들 회의결과 :**
유빈님 : test 데이터에는 가격이 없어서 train데이터만 기준으로 잡고 분석을 해도 되겠다.
성환 : test데이터는 동일한 통계량과 결측치로  stg2의 데이터를 사용.
유빈님 진행질문후 : 예측으로 할건지 비즈니스쪽 관점으로 할건지 우선 정하는것이 좋을거 같다는 피드백으로
유빈 : 결정 케이스 2개

1. 대량의 데이터로 분석할건가? price데이터가 유용하다면 train만 사용
2. price데이터를 버리고 분석할건지?
3. 상혁 : train데이터 사용하는건 찬성 test데이터는 price는 없지만 train데이터를 보고 먼저 분석방향을 생각하고 Train데이터를 분석

가설 검증 : 별도로 기록

**가설 검증 선택시 회원들간 고민**
가설 검증에 대한 Why를 생각해 봤습니다. 이런 가설이 왜 필요하고 누구에게 도움이 될까? 조원들끼리 생각했을때는 판매자에게도 본인이 높은가격을
원하거나 낮은가격이지만 급하게 팔려고 할때는 이런 필요한 서비스가 도움이 될것이고 구매하는 입장에서도  본인이 시간적인 여유가 있다면 가격이 
낮더라도 기다릴것이고 급하면 가격이 높더라고 선택을 한다는 입장이며, 이런 서비스가 활성화 되어 있다면 이런 플렛폼을 운영하는 비즈니스적인 
회사입장에서도 필요한 서비스를 구축하기 위해서 필요한 가설이라고 판단됩니다.

성환 - 데이터 중에 판매된가격이 없어서 아쉬운데 판매가격을 임의로 만들면 어떨까? 예를 들어 랜덤으로 기존가격에서 +-20% 안에서 특정가격을 
판매가격으로 한다던가.

상혁 - 기존 가격들의 평균을 계산하여 해당 평균아래의 가격들의 금액은 판매금액으로 새로운 컬럼으로 만들자

공통 : 새로운 컬럼으로 판매금액을 만들어 활용해보자. 

**2/24 17:50까지의 Main Quest 04 Project 진행 사항**
전체 4일중 2일째 가설설정하기 까지 진행되어 계획
대비 Ahead 상태로 이후 진행에서 만약에 지체될
경우를 위해서는 양호한 진행속도임. (지금까지의 
진행속도로 on going) 

---

**2일차(2/25) :** EDA와 feature engineering / 분석 전략 수립

- 조별로 가설설정 해보기
- 프로젝트 계획세우기(일별/시간별)
- 데이터 전처리
    - 결측치 처리 방법 논의 / 결측치 채우기
    - 이상치 탐지

오늘은 유빈님 개인사정으로 부재중이나 프로젝트진행에 차질이 없도록 진행과정을 세부적으로 기록하여 금일 부재중으로 인한 영향이 없도록 하겠습니다.
금일 분석목표 작성필요
헌수 - 팀장 : 오늘 진행사항에 대해 오전에 전처리, 이상치 정리, 텍스트 소문자로 변경. 오후에 유빈님 투입되시면 같이 레츠 기릿 
상혁 - 한사람이 코드 작성하고 나머지는 코드작성한거 보고 피드백을 줄수 있을거 같긴한데 코딩을 두사람이 한다고 하면 한사람은 발표자고 한사람은 
팀장이라고 하면 맞는거 같긴한데 회의적이다. 헌수님처럼 각자 역할에 맞는 코드를 작성해서 하나로 취합, 승욱님 피드백으로 하면 한사람이 코드를 치고
공유해서 보면서 나머지는 코드를 보면서 피드백을 주는걸로 하는것으로 수정보완하는 방법으로 하는방법으로 하는게 좋을거 같다. 
성환 - 상혁님이 전에 진행했을때는 어떻게 했는지 
상혁 - 같은 상황은 아니지만 각자분담을 하고 한번씩 모여서 발표하고 내가 시도 했으나 문제점이 있고 대응해서 결과에 대해 서로 피드백하면서 
진행하는것으로 했는 연구실에 진행하는 연구가 많아서 그렇게 했었다.  다른 프로젝트는 분담을 해서 하는 식이다. 특정분야에서의 전문가가 있어서 
전문에 맞춰서 진행하고 피드백을 하는것으로 진행하는것으로 했었다.
상혁 - 같은 프로젝트도 그렇게 했었다.
팀장 - 상혁님은 어떤방식이 좋을까요?
상혁 - 각자 어느정도 분담해서 각자 진행해서 취합해서 피드백하고 하는식으로
발전할수 있다.  두번째는 한사람이 코딩을 하고 다른사람이 코드를 보고 피드백하면서 진행하는식으로 
성환 - 같은 분야에대한 분담인지? 전처리, 결측치, 이상치 등을 전부 나눈다든지?
상혁 - 이상치는 특정 칼럼에 대해서 이상치가 있을수 있고 특정칼럼으로 정리하는것도 좋을듯, 서로 역할 분담을 하되 독립적인게 최선일거 같고
성환 - 그럼 현재 오늘 진행하는 것이 순서대로 진행해야 하는지 아니면 순서와 상관없이 가능한지?
상혁 - 이상치라고 해서 다순히 제거가 아니라 살릴수도 있어서 A라는 분석의 이상치를 정리한 데이터플레임으로 분석하고 B라는 분석의 이상치처리한 
데이터플레임으로 하는 방법이 있어서 특정방향성에 대해서는 역할 분담을 하고 진행을 한뒤에 나중에 의견취합하는 방법이 세분화적으로 진행되지 않을까
하는 생각이 있다. 혼자서 코드 진행하고 다른사람이 피드백은 각자하는거 보다는 방향성은 있지만 세부적인 디테일에는 부족함이 있을거 같다.
성환 - 시간과 일정을 생각했을때 방향성을 다양화 하기 위해서는 각자 하는것이 더 다양성의 면에서 더 유리하지 않을까 생각합니다.
상혁 - 세부적으로 나눠서 하는 방식이 진도가 느리더라고 일정에는 무리가 없고 세부적으로 넓게 해 보는 방법도 좋도 앞으로 진행일정에 문제는 없을거같다.
헌수 - 어제 승욱님에 이야기를 듣고 한사람이 코드를 할 경우 다른사람은 무엇을 하나라는 의문이 있어서 두분이 그런 생각이면 다 나눠서 해도 괜찮을거
같은데 제생각은 코드 취합합시다 했는데 제가 잘못했을때는 또 다시 해야 되니까 걱정이다
상혁 -  나중에 피드백을 하면서 그때 수정하면 되니까 그건 문제가 안될거 같다. 그때 그때 진행해서 수정하면 되니까 본인이 할수 있는 만큼 해서 
진행하면 되지 않을까 생각합니다.
성환 - 다양성의 기준에서 세부적으로 나눠서 하는것이 좋을거 같습니다.
성환 - 일거리를 나눠서 하는거에 대한 구체적인 방법?
상혁 - 이상치, 결측치, 전처리 등도 하다가 막히면 서로 의견을 나누는 것이 
헌수 - 오전에 성환님께서 말씀 하신대로 한 번 해보고 오후에 다시 의견을 나눠서 오전에 한게 있으니 어떻게 하는게 좋겠다고 유빈님 오시면 다시 얘기
나눠보는게 어떨까 싶습니다. 오후에 유빈님 오시면 의견 들어보고 최종 방향성 맞춰보자는 거죠?
헌수 - 다른조 정찰 다녀 오겠습니다. 어떻게 하라는 정답은 없는거니까.
상혁 - 계획세우기에서 3일치의 해야되는 부분을 봤을때 결측치, 등 오늘 진행을 중점적으로 해도 되지 않을까? 각자 해보면 3일치의 내용도 나올거 같다.
성환 - 오늘의 계획은 전처리, 결측치, 이상치 탐지 를 금일 2시까지 하는걸로
상혁 - 12시에 중간체크 한번 중간점검 
팀장 - 다른팀의 진행사항에 대해 의견나누고 소통함. 

**중간체크(12:00) 유빈님 합류(전체 조원 다같이 중간체크)**

**결측치 처리 방법 논의/결측치 채우기**
성환 -결측치를 unknown으로 했는데
상혁 - 카테고리에 별 내용이 없어서 결측치를 지워야되나 생각해서 카테고리 , 브랜드네임은 성환님처럼 변경했다. 아이템 디스크립션은 내버려뒀는데 
결측치로 체워야 된다고 생각한다.
성환 - 중복된 값은 없었다
상혁 - describe 내용에 대해 설명, 브랜드 네임은 의 ...값은 이하생략이여서 브랜드 네임의 유무성으로 만으로 따져야 되겠다. unknown 이냐 아니냐로
하면 될거 같다. price의 경향이 500이하가 집중적으로 많았다. 값싼것이 주로 거래가 많은경향이고 컨디션은 1~5까지 중 에서 
성환 - 컨디션부분에서 4,5부분이 비율이 너무 적어서 없어되 되지 않을가?
상혁 - 컨디션부분에 대해서 전담하는 사람이 더 분석을 해보고 판단하는게 좋을거 같다.
유빈 - 컨디션의 순서가 1-3-2-으로 및 오늘 추가되는 컬럼을 만들기로 했다 카테고리별 평균금액, 긍정부정갯수, 판매완료금액 
상혁 - 해당 컬럼중에서 집중적으로 나눠서 특정컬럼에 대해서 나눠서 추가하고 나누고 진행하고 다시 모여서 방향성을 가지고 취합해서 방향을 해보는것을
이야기 했었는데 앞으로는 지금처럼 진행하는게 나을지? 아니면 특정컬럼별로 분류 분석해서 논의하고 공유해서 취합해서 하는게 나을지?
유빈 - 그부분 동의하며 지금까지 이상치 결측치 진행한것을 코렙에 업데이트하면 될거 같고 각자 맡은 파트를 정해보자
아이템 description에대해 해보겠다. 카테고리에 대한 정리가 필요하다. 
상혁 -  카테고리를 나눠서 코렙에 공유를 하고 브랜드는 있냐 없냐로 진행을 해야 할거 같은데 
공통 - item_condition_id , brand_name, price, shipping에 대해서 더 집중적으로 검토를 해보자 
상혁 - 카테고리 측에서 브랜드를 볼려면 브랜드를 담당하는사람과 서로 상의하는방식으로 하자 동의 
유빈 - 브랜드 하시는 분이 컨디션과 원앤 아이디로 묶는다던지 컬럼을 정리하면 
유빈- 컨디션같은 경우 1~5를 상중하로 분류해 보는것도 좋을거 같다.
price를 그때 검토해 보는게 좋을거 같다.
헌수 - 브랜드네임과 아이템컨디션 하겠다.
상혁 - 브랜드 네임
유빈 - 카테고리를 합치는과정이 시간이 많이 걸릴거 같다.
상혁 - 카테고리 전담은 상혁님이 전담하고 기타 정리는  성환과  같이 하는걸로
유빈 - 컨디션컬럼은 1,2는 최상, 3,4는 중, 5는 또는 12, 3, 4,5 같이 찾아줬으면  
공통 - 1을 상으로 2,3 중 같이 4,5를 하로 상, 중, 하 로 분류하자
상혁 - 브랜드 네임을 나눠서 분석시도 해봤는데 unique값이 ... 이 ? 이며, 4809개가 있어서 우선적으로 브랜드 네임이 있느냐 없느냐로 나눠서 
판단해보는게 좋을거 같다. 이미 결측치값을 성환님이 진행했기때문에 코랩으로 올려주면 헌수님이 진행하는거로
유빈 - 브랜드 네임을 통합할 수 있는 부분이 있는 지도 추가적으로 검토 필요
상혁님 : category_name 일때 어느 컬럼과 연관관계를 알아보는게 좋을까?
공통 - 카테고리 분류가 중요할거 같다.
상혁 - 카테고리분류작업 후 메인은 10가지 인거 같다
유빈 - 카테고리에 메인 카테고리기준으로 보되 other에 대한 값을 조금더 세분화 하자.
가격중에 0으로 되어있는것이 있는데 이것은 중고거래 사이트에서 특이한 케이스로 0금액은 제거하는쪽으로 
유빈 - 메인 카테고리에 키워드를 트랜드를 넣는거다 3년전 검색량대비 인기도에 대해서 unknown에 대한건 그냥 살리는걸로 
other, beauty, kids, home, women, 
유빈 - 텍스트 데이터 사전불러와서 컬럼작성 예정 apply부분에서 
브랜드 네임의 비슷한것을 단순화 하는 방법으로 
상혁 -  판매여부에 대한 기준 특정값보다 작을때 판매완료로 컬럼추가 
가격의 평균치(대신에 상관관계를 보고도 판매여부확정)에서 작으면 판매했을거다라면 각각 카테별로 
팀장 - 제품 컨디션에 상, 중, 하 분류작업 하는 너무 적게 나왔다. 

금일체크(17:50) 오늘은 늦게까지 최대한 작업을 해보자는 의견으로 야근? 예정 
전체 4일중 2일째 진행되어 계획
대비 Behind 상태로 Catch-up위해 금일 늦게 까지 작업진행 예정
금일 데이터 전처리 과정과 컬럼 생성에서 진행속도 늦어짐. 
category = train_df['category_name'].str.split('/').apply(pd.Series)
category = category.rename(columns={0: 'main_category', 1: 'sub1_category', 2: 'sub2_category',  3: 'sub3_category', 4: 'sub4_category'})
merged_df = pd.merge(train_df, category, left_index=True, right_index=True, how='inner')
※ apply적용시 속도오래 걸리는 문제로 아래 코드로 대체시 속도가 빨라짐
문자열 분할 시 expand=True 옵션을 사용하여 DataFrame을 바로 반환한 후, DataFrame의 join() 메서드를 사용해 병합하는 방식으로 
코드를 최적화. apply(pd.Series)를 사용하는 것보다 훨씬 빠릅 아래 코드로 변경실행
# category_update: 최적화된 코드
category = train_df['category_name'].str.split('/', expand=True)
category = category.rename(columns={
    0: 'main_category', 
    1: 'sub1_category', 
    2: 'sub2_category',  
    3: 'sub3_category', 
    4: 'sub4_category'
})
# DataFrame.join()을 사용하여 병합 (인덱스를 기준으로 합침)
merged_df = train_df.join(category)

상혁 - 핑크 브랜드 데이터  브랜드 담당은 top100에 속한 브랜드는 1 속하지 않으면 0으로 해서 컬럼을 추가 작업 헌수님
유빈 - 스플릿하지 않은 가격으로 평균가격을 구하기로 카테고리는 상혁님이 해주신걸로 정리 브랜드는 Top 100에 속한 브랜드는 1 
속하지 않으면 0으로 해서 최종 데이터로 정리예정
상혁 - brand_name 에 위치한 PINK 데이터 분석해보니 electronic이라는 이상치가 확인되어 제거후, csv 파일로 공유 예정, 
데이터 분석 결과 PINK 는 여성 속옷 파는 브랜드일 가능성이 높다는 결과가 나타남. 결측치는 unknown값으로 채워서 CSV파일로 마무리.

**금일체크(22:50) 데이터 컬럼중 중요한 브랜드, 카테고리별로 팀원들 토의후 결론**
1. 스플릿하지 않은 가격으로 평균가격을 구하여 추가 컬럼으로 생성, 
2. 카테고리는 상혁님이 해주신걸로 마무리 하여 정리
3. 브랜드는 Top 100에 속한 브랜드는 1 속하지 않으면 0으로 해서 추가 컬럼생성하여 정리
4. brand_name 에 위치한 PINK 데이터 분석해보니 electronic이라는 이상치가 확인되어 제거후 csv로 공유
5. 결측치는 unknown값으로 채워서 CSV파일로 마무리.

***[[[[[[[[[[[[[[[[[[[[[[[[[[[[ 중간 진행사항 체크 및 평가 ]]]]]]]]]]]]]]]]]]]]]]]]]]]--------------(2025-02-25(화))***

1. 팀 빌딩 및 역할 분담
팀 빌딩 및 아이스브레이킹:
초기 아이스브레이킹을 통해 팀원들이 서로의 강점을 공유하였으며, 프로젝트 진행 방향에 대해 논의하였습니다.
역할 분담:
팀장 (프로젝트 리더): 헌수님 (최종 결정: 헌수님이 팀장으로 선정)
데이터 엔지니어: 전처리, 데이터 품질 검증, 분석 환경 구축
데이터 분석가: EDA 수행, 통계적 분석, 인사이트 도출
비즈니스 분석가: 데이터 관련 트렌드 분석, 비즈니스 관점 인사이트 도출
각 팀원은 자신이 잘하는 분야에 따라 추가 역할도 맡기로 결정 
(예: 유빈님은 코딩과 발표자료 작성, 상혁님은 발표 및 카테고리 정리, 성환님은 전체적인 서포트 및 역할 분담 조율, 헌수님은 팀장으로 전체조율 및 의사소통)

2. 분석 플랫폼 및 협업 도구 결정
플랫폼 논의:
코랩(Colab)과 GitHub 중 어느 것을 사용할지에 대해 의견이 모아졌으며,
결론: 팀원 대부분이 코랩 사용에 익숙하고, 별도의 깃허브 설정 없이 빠르게 진행할 수 있으므로 코랩을 기본 협업 도구로 사용하기로 결정.
파일 경로 문제: [문제점 및 해결방안]
각 조원이 자신의 구글 드라이브 경로를 사용해 데이터 파일을 불러오는 방식으로 진행하여, 환경 차이 문제를 인지하고 공유 시 최종 정리 시 경로를 
통일하기로 함.

3. 데이터셋 및 전처리 현황
데이터셋 크기:
train.tsv: 1,482,535 행 × 8 컬럼
test.tsv: 693,359 행 × 7 컬럼 등
stg2 데이터셋도 확인되어, test 데이터는 stg2 데이터를 활용하기로 결정함.

**전처리 작업:**
 - 결측치 처리:
   category_name, brand_name, item_description 등에서 결측치가 발견되어, 각 컬럼마다 적절한 방법(예: 결측치를 unknown으로 처리)으로 보완함.
 - 이상치 탐지 및 처리:
   price 컬럼에 대해 IQR 기반 이상치 탐지 후,
   Winsorization: 극단값을 상한(약 57.5)으로 제한하여 분포 왜곡 완화
   이상치 제거: IQR 범위를 벗어나는 값들을 제거하여 새 데이터셋 생성
   결과적으로, 이상치 처리를 통해 평균과 표준편차가 안정된 분포를 얻었으며, 추가 시각화를 통해 분포가 분석 및 모델링에 적합한지 확인함.

**카테고리 분할:**
 - category_name 컬럼을 슬래시(/)를 기준으로 분할하여,
   main_category, sub1_category, sub2_category, sub3_category, sub4_category로 나누고,
   최적화: 문자열 분할 시 expand=True 옵션과 join()을 사용하여 속도 문제를 해결함.
**브랜드 처리:**
 - brand_name 컬럼의 결측치가 많아,
   결측치는 unknown으로,
   비결측치는 known으로 변환하는 이진 처리 방식을 적용하여,
   나중에 Top 100 브랜드 여부로 추가 컬럼 생성하는 방향도 논의됨.
**추가 생성 컬럼:**
 - 판매완료 금액이나 평균가격 등 새로운 컬럼 생성 아이디어가 제시됨.

**4. 가설 설정 및 분석 전략**
가설 설정:
 - 분석 전 가설 설정의 중요성이 강조됨.
   예를 들어, 판매자와 구매자 모두 가격 및 배송 조건에 따라 거래 패턴이 달라진다는 가설이 제시됨.
   가설 검증 결과를 통해 비즈니스 인사이트 도출에 집중하기로 함.
비즈니스 관점:
 - 데이터에 기반한 서비스 개선, 예를 들어 가격과 배송 조건에 따른 최적 거래 전략을 모색하는 방향이 논의됨.

**5. 회의 및 진행 상황 평가**
진행 상황:
 - 4일 중 2일째까지 전처리, 결측치 처리, 이상치 탐지 및 일부 컬럼 분할 작업이 완료됨.
 - 일부 작업(예: 브랜드 Top 100 여부, 추가 판매금액 컬럼 생성 등)은 진행 중이며, 향후 협의하여 최종 결정 예정.
 - 데이터 파일 경로 문제 등 환경 설정 문제는 팀원 간 협의를 통해 해결된 상태.
팀원 의견:
 - 팀원들은 역할 분담과 협업 방식에 대해 긍정적인 피드백을 주었으며, 추가 피드백 및 수정사항은 실시간 공유하여 진행하고 있음.
 - 팀장 역할 및 진행 상황에 대해, 팀원 간 의견이 모아져 앞으로의 일정과 책임 분담을 명확히 하는 방향으로 진행하기로 결정.

***[종합 평가]***
 - 진행 속도:
    전체 4일 중 2일째까지 계획대로 진행되었으나, 일부 전처리(예: 문자열 분할 속도 개선) 및 파일 경로 설정 등에서 시간이 소요되었음.
 - 문제 해결:
    데이터 전처리와 이상치 처리에서 발견된 문제를 적시에 해결하며, 팀원 간 소통과 피드백을 통해 개선 중임.
 - 향후 계획:
    추가 컬럼 생성 및 가설 검증, 모델링 단계로 진행하며, 각자 맡은 부분을 계속해서 진행하고 최종 분석 결과를 취합할 예정.
    비즈니스 인사이트 도출 및 발표 자료 준비에 집중할 계획임.
중간 진행사항 체크 및 평가(02/25 23:10) 

**3일차(2/26) : EDA와 feature engineering / 데이터 해석**

각 변수끼리의 상관관계 분석
경향성, 패턴 등을 통해 인사이트 찾아내기
인사이트를 통한 활용 방안 고민
세운 가설을 시각화를 통해 증명하기

진행방법 예시
1. 역할 분담:
팀원 1: 기본 통계량, 분포 분석, 히스토그램 및 박스플롯 등 기초 시각화 담당
팀원 2: 변수 간 관계 분석 (상관관계, heatmap, pairplot 등) 담당
팀원 3: 특정 그룹이나 범주에 따른 집계 및 인사이트 도출, 예를 들어 바 플롯이나 그룹별 비교 시각화 담당
팀원 4: 가설 설정 및 증명을 위한 시각화와 통계적 검증 담당

2. 협업 도구 활용:
 - 코드 버전 관리: GitHub를 사용해 코드를 공유하고, 각자의 작업 내용을 Pull Request로 검토.
 - 커뮤니케이션: 슬랙, Microsoft Teams, 혹은 정기 미팅을 통해 진행 상황을 공유하고, 발견된 인사이트나 문제점을 실시간으로 논의(ZAP 소통).

3. 작업 분할 및 통합:
각 팀원이 독립적으로 분석한 결과를 정리한 후, 공통의 프레젠테이션이나 리포트에 통합하여 전체적인 인사이트를 도출.
분석 결과와 시각화 자료를 공유 폴더나 협업 툴(Google Drive, Notion 등)에 저장 전체 팀이 접근할 수 있도록.

**역할분배 검토예시(팀원들과 상의)**
팀원 1 (기초 시각화: 기본 통계량, 분포 분석, 히스토그램, 박스플롯)
→ 팀원 B: 성환
코딩 경험은 적지만, 기초 통계와 간단한 시각화는 튜토리얼을 참고하며 쉽게 수행할 수 있으므로 배정합니다.

팀원 2 (변수 간 관계 분석: 상관관계, heatmap, pairplot)
→ 팀원 A: 상혁
대학원 연구 참여 및 발표 경험이 있어, 데이터의 복잡한 관계와 시각적 분석(예: 상관관계 히트맵, pairplot) 작업에 적합합니다.

팀원 3 (그룹별 집계 및 인사이트 도출, 바 플롯/그룹별 비교 시각화)
→ 팀원 C: 유빈
SQL과 레포트 작성 경험이 풍부하며, 데이터 집계 및 도출한 인사이트를 효과적으로 정리할 수 있으므로 이 역할에 가장 적합합니다.

팀원 4 (가설 설정 및 증명을 위한 시각화와 통계적 검증)
→ 팀장 D: 헌수
다른 업종에서의 경험과 뛰어난 의사소통 능력을 바탕으로 팀장을 맡아, 가설 설정 및 시각화, 검증 과정을 주도할 수 있습니다.

**시간 계획 목표**
10:30 ~ 11:00 – 킥오프 미팅 및 역할 확인
전체:
팀장 헌수님 오늘 진행할 작업의 개요와 목표를 공유
각 팀원(성환, 상혁, 유빈)이 맡은 역할 및 세부 과업 간단하게 리뷰
사용 도구(코드 버전 관리, 공유 폴더, 커뮤니케이션 채널 등) 최종 점검
11:00 ~ 12:50 – 개별 작업 진행
팀원 B (성환)
기본 통계량 산출, 분포 분석
히스토그램, 박스플롯 생성 (기초 시각화 코드 작성 및 실행)
팀원 A (상혁)
변수 간 상관관계 분석: corr() 계산, heatmap, pairplot 작성
팀원 C (유빈)
그룹별 집계 및 바 플롯, 그룹별 비교 시각화
SQL 혹은 Python 코드로 필요한 집계 작업 수행
팀장 D (헌수)
가설 설정을 위한 초기 아이디어 정리 및 관련 변수 선택
가설 증명에 필요한 통계적 검증 방법(예: 회귀분석, t-test 등) 계획
12:50 ~ 13:50 – 점심시간
13:50 ~ 15:00 – 중간 점검 및 결과 공유
전체 회의:
각 팀원이 진행한 작업 결과를 공유
상혁: 상관관계 분석 결과 및 시각화 자료 설명
성환: 기본 통계량 및 분포 시각화 결과 공유
유빈: 그룹별 집계 결과 및 시각화 자료 설명
헌수: 초기 가설 아이디어와 검증 계획 공유
토론:
인사이트 도출 및 활용 방안 논의
각 시각화 결과를 종합하여 추가 분석 방향 결정
15:00 ~ 16:30 – 가설 증명 및 심화 분석
팀장 헌수님 주도 하에:
세운 가설에 맞춰 추가 시각화(예: 산점도 + 회귀선 등) 및 통계적 검증 코드 작성
팀원들이 각자 보완 작업 수행하면서, OO님이 결과물을 통합
협업:
필요시 코드 리뷰 및 추가 조정 (GitHub Pull Request 활용)
16:30 ~ 17:00 – 최종 코드 통합 및 리포트 작성
전체:
각 팀원이 작업한 코드를 통합하여 최종 분석 스크립트 작성
시각화 자료, 인사이트 정리 및 가설 검증 결과를 리포트에 반영
17:00 ~ 17:50 – 최종 점검 및 발표 준비
전체:
최종 발표 자료(프레젠테이션, 리포트) 작성
시각화 및 결과에 대한 최종 검토 및 피드백 반영
발표 리허설 및 역할 분담 점검
성환 - 기본 일정 및 계획 공유 및 파일관리 서로 공유 필요할듯합니다.
공통 금일 일정 및 역할 분배에 대해 검토
유빈 - 브랜드관련 정리 헌수님이 해주셨고, 
팀장 - 전일 상혁님이 피드백주신 내용
상혁 - 저한테 있습니다. 
유빈 - 최종 데이터셋은 조정이 필요한지
상혁 - 최종 정리된거라 불러오면 되고
유빈 - 텍스트 붙인데이터를 처리하면 될거 같다. 상혁님의 로컬 작업으로 해서 코드 적용이 안되서 
상혁 - 스플릿 로딩이 오래걸려 로컬로 했는데 유빈님 공유에 올리겠습니다.

유빈 - df_text_combined.csv는 clean_data.csv 이기반으로 작업한 파일이다.
오늘 진행해야되는 건 최종데이터 로딩이 되면 팔렸다, 안팔렸다 평균가격구해서 컬럼 추가 하고 거기서 변수별로 팔렸다, 
안팔렸다의 상관관계로 마무리 하면 될듯
역할 분담이 필요하다
상혁 - 상관관계를 해야되는건 맞다. 유빈님이 아이템 디스크립션으로 하는 결과 헌수님이 했던거 보고 개인적인 의견들였던거 말씀드리면될듯
유빈 -아이템 디스크립션을 분석해서 데이터 기반으로 긍정, 부정을 포함해서 분석하기로 했다. 그래서 긍정어 100개, 부정어 100개 리스트 업했고 
그전에 단어의 갯수를 그래프로 해봤고 단어50개 이내가 대부분이였고 가격과 단어갯수와의 상관관계를 산점도로 보니, 
상혁 - 아이템 산점도에 끝에 부분에 길이가 상당히 길면 부연설명이 많아서 가격이 0에 가깝게 낮은데 길이가 커서 이부분을 따로 검수해 보면 
뭔가 나올거 같은 느낌이다. 이부분(200~250)만 따로 추출을 해서 검토해보자
상혁 - 기존에 실행했던 파일을 최종데이터셋이라는 곳에 최종파일과 CSV를 같이 넣겠다.
상혁 - 100~150에 부분을 따로 분석하는것도 좋을듯 하다.
유빈 - 아이템 디스크립션의 자연어 및 영어 특성상 의미없는 단어 be동사 전치사 들을 지워 줄수 있는 패키지를 가져와서 지웠다. 긍정어 부정어 
사전을 만들어서 제품상태 관련해서 기준으로 리스트 업해서 이 사전을 기준으로 텍스트를 전처리 하고 엔터기준으로 토큰화해서 불용어 제거 하고 
영어의 과거형 진행형을 어간으로 만들어서 진행해서 최종 결과는 Clean데이터 기준으로 만들어서 단어길이, 단어개수를 컬럼으로 만들었고, 
사진기준으로 몇개로 되는지 카운트 컬럼 생성했고 어떤단어가 매핑이 되었는지 등 총 5가지 컬럼을 추가 생성했다. 이런 컨디션에 긍정, 
부정에 영향이 있는지? 가격적인면으로 영향이 있을까? 팔리고 안팔리고에 영향이 있을까 검토위해서 준비 했다.
상혁 - 유빈님과 이야기 했던 트랜드 관련 헌수님거보고 개인의견드린건데, 일단은 트랜드 데이터 같은경우는 어떻게 할지 말지 정해야 하는 
부분이기도해서 트랜드는 뒤로 미루고 헌수님거부터 high, middle, low에 따른 category main 분류를 통해 high, middle, low 각각 비중있는 
category 분석 진행 middle 부분의 값 평균이 높은 이유가 상대적으로 값이 높을 electronics 제품들이 모여있을 가능성이 클 것 같아 보임. 
이전 brand_name 과 category 분포도를 통해서 확인한 결과 women 제품들이 제일 비중있게 나타났으며 electronics 보다는 여성 의류, 
속옷 브랜드가 제일 많이 판매되었음
high 부분에 있는 category가 값이 상대적으로 저렴한 여성 의류 제품이 몰려있을 가능성이 커 보임
해당 중고거래의 타겟팅을 여성으로 진행하고 홍보하는 것이 중고거래의 활성화에 도움이 될 것 같음. 
여기까지가 상, 중, 하의 가격 평균을 그래프에 대한 저의 개인적인 분석입니다
# shipping 별 평균 가격 계산
0의 가격이 1보다 평균 금액이 높음. category에 따른 가격의 편차가 크다는 점을 감안하여 특정 category별 shipping 분석과 같은 세분화가 필요해보임. 
가령 electronics는 shipping이 0인 방향으로 거래되는 경우가 많아서 단순 전반적인 shipping 분석 결과가 0이 price 평균값이 높다고 나왔을 
가능성이 있어보임. 아닐수도 있음
# 구매자가 배송비를 부담하는 상품은 상대적으로 더 비싼 상품일 가능성이 정말 있을까?
boxplot이라 다양한 부분들을 비교 분석할 수 있다는 장점이 있긴 하지만 이전에 막대그래프로 나타낸 분석 이상의 유의미한 결과가 보이지 않음. 
# 배송비 부담(shipping)과 가격(price) 사이의 상관 관계 분석 : 강하지 않으나 두 변수 간 반비례 관계성은 확인됨. 가중치를 두어 분석한다던지 
category 별 shipping 분석하면 뭔가 유의미한 값이 나올 것 같음
# 히스토그램 그래프로 확인
분석은 좋은데 y 값이 count라서 상대적으로 높다 낮다를 분석하기에는 좀 부족해보임. 퍼센테이지로 상대성을 나타냈으면 보다 좋은 상관 분석이 
될 것 같음. plt.xlim(0, 200) # 이상치 제거 : 이런 디테일이 이미 적용 되어 있어서 상관관계를 퍼센테이지로 나타내어 그래프로 보여주면 
좋을 것 같음
print(train.groupby('has_brand')['price'].mean()) 
# 브랜드 유무에 따른 가격 차이 분석
category 별 분석 없이 전반적인 흐름으로 보아도 브랜드가 있는게 값이 크다는 결과가 나와서 전반적으로 모든 category에서 브랜드가 있는게 
더 가격이 높다는 결과로 나타내기 좋은것 같음
그러나 category 별 브랜드 유무에 따른 가격 차이도 추가적으로 있으면 앞서 진행했던 일반화한 '# 브랜드 유무에 따른 가격 차이 분석' 이 
더 신뢰성을 가질 수 있을 것 같다는 생각이 듦
우려되는점은 condition에 따른 구분을 우선적으로 하고 브랜드 유무에 따른 가격 차이를 진행하지 않은 결과라서 값의 정확도는 조금 떨어질 수 
있을것이라 생각됨. 이전에 condition 값을 상,중,하로 나누어서 진행했던 값을 토대로 상, 중 값이 상대적으로 크게 차지한다는 점을 고려한다면 
그래도 유의미한 값으로 주장할 수는 있을 것 같음
상혁 - 제품 컨디션 그래프의 평균값으로 그래프를 봤을때 중간값이 가장크고 대부분 비슷하며 산점도는 0~60까지의 가격이 상당히 높다. 
상대적으로 가격이 높은 전자 제품이 미들쪽에 많이 적용되어 있어서 컨디션이 상인게 중간에 모인게 아닌가 판단하고 컨디션의 분포를 확인해서 
세분화 해서 봐야 경향성이 보이지 않을까하는 느낌이고 High부분이 여성쪽이 상당히 많다. Women쪽이 상당이 많고, 브랜드는 PINK가 상당이 많다 
결국 Pink가 여성쪽이여서 그런게 아닌가 해서 해당 중고거래 사이트는 여성거래자가 상당히 많을거라고 판단해서 여성쪽을 타겟으로 하는게 
좋치 않을가 판단이된다. 배송그래프는 사는사람이 돈을 부담하는게 높다는 결과가 나왔다. 가격범위가 상당히 넓어서 세분하 시켜서 경향성으로 
분석해야하는데 그렇게 안했는데도 타당성 있게 보인다. 카테고리별로 분류하면 (전자제품, 의류 쪽 이렇게 해보면 결과가 똑같이 나올거 같다) 
평균적으로 구매자가 부담이 높다.  박스플롯도 비슷한 결과다. 배송비부담과 가격의 상관관계분석해보니 강한 연관성은 없는데 결과값으로 -10%로 이면
무시하기 는 좀 큰 분포이다. 
브랜드 인기도(Top100에 대한 컬럼 추가해야
 컨디션의 분포를 확인해서 세분화 해서 봐야 경향성이 보이지 않을까
배송비와 가격이 반비례관계인데 이것도 카테고리 별로 보던지 나눠서 분석해야 할거 같다.
상혁, 유빈 - 단순히 price 부분으로서만 바라보기 보다는 trand data 경향성도 보면서 특정 시각을 기준으로 검색량이 많은 정도를 column 값으로 
넣어서 팔릴 것인지에 대한 예측 column의 변수로서 사용한다면 보다 정확한 판매 예측 column을 만들 수 있을 것이란 기대가 있음. trand data 값을
특정 시각에서 뽑아오는 것이 아닌 전반적인 흐름까지 고려한다면, 만일 trand data가 시간에 따른 움직임이 일정한 패턴을 보인다면 이를 기반으로 
앞으로 중고거래에서 어떤 제품이 많이 거래될 것이지를 예측할 수 있는 지표로서 사용 할 수 있을 것 같음.
(특히 애플이나 삼성같은 경우에는 특정 기간마다 새로운 제품을 판(특히 애플이나 삼성같은 경우에는 특정 기간마다 새로운 제품을 판매하는 
경향성이 있기 때문에 시간에 따른 trand data가 반복적인 그래프 모습을 보일 것 같음)

유빈 - 과거 데이터 대비 5년동안의 데이터로 트랜드로 감안하여 검색 비중으로 구글트랜드에서 검색하여 검색비중의 증가율을 트랜드 지수로 하면 
어떨가? CSV파일로 다운 받아서 한사람당 열개씩 분석할수 있을거 같다. 하는 이유는 해당 카테고리의 상품이 많이 팔렸나. 비교할때 가격의 단위와 
차이에 서로 비교할때 외곡되는 문제는?
성환 - 단위와 수치가 다를때는 각 각의 비율로 해서 비교하면 외곡이 거의 없어지므로 그렇게 하면 될듯 합니다.
유빈 - 5개중 검색량이 괭장히 높은게 있는데 
상혁님 - 카테고리별 평균가격을 넣고 가격이랑 카테고리별 평균가격비교해서 가격이 높으면 안팔렸다, 낮으면 판매됬다 두가지로 
price랑 카테고리 별 가격 분석해서 price가 높은 것과 낮은것 0과 1 값으로 구분하는 행 만들기
유빈 -  코드 취합보다는 
성환, 유빈 - 트랜드 데이터를 수집 정리같이
공통 - 최종파일관리는 최종 데이터셋폴더 안에 project4_semifinal.ipynb, output_semifinal.csv 에 정리하는것으로 합시다

**중간체크(14:30) 오전 작업한 내용에 대한 토의(문제 및 해결협의)
성환 - 구글 트랜드에서 5년전 추세 정보 다운시 수치가 너무 차이나는것은 값이 0로 보이는 문제점 → 카테고리 하나씩 조회해서 정보 받기로 유빈님추천
이후 작업으로 37개 카테고리 조회및 정보취합(취합중 문제점 vintage & collectibles 단어의 경우 조회가 안되거나 수치가 0이 많을경우는 → 대체방안
vintage 값으로만 조회하거나 뒤에 -s를 붙여서 조회해 보니 결과가 괜찮아서 이방법으로 함, 0인수치 많은 카테고리는 다시 조회 앞단어로 또는 s를 
붙여서 조회하여 되도록 0수치가 없는 수치로 정보수집함) ▶ 이후 수치원본을 각개별 카테고리별로 비율을 계산하여 % 로 표시한 것과 수치로 표시한 자료
두개 로 준비함.
헌수 - plt.figure(figsize=(8, 5))
sns.barplot(x=train_df["shipping"], y=train_df["price"], palette="coolwarm", estimator=sum)
plt.xlabel("Shipping (0: Buyer Pays, 1: Seller Pays)")
plt.ylabel("Average Price")
plt.title("Average Price by Shipping Type") 해당 코드에 대한 로드시간 오래걸리는 문제
상혁 - output_semifinal3.csv 파일을 카테고리별 평균 가격 행 만들기
price랑 카테고리 별 가격 분석해서 price가 높은 것(1)과 낮은것 0과 1 값으로 구분하는 행 만들기
유빈 - 그걸로 word 업데이트해서 4version으로 다시 올리겠습니다 :) output_semifinal4 버전 업로드했습니다.
작업하시는 분들은 이걸로 작업 부탁드립니다. # output_semifinal1 : 긍부정어 개수 +카테고리 수정 통합본
# output_semifinal2 : 카테고리별 이름 수정 추가
# output_semifinal3 : 카테고리별 평균 추가
# output_semifinal4 : 긍부정어 work, works 개수 수정본
성환 - brand_names.xlsx 그래프 수정했구요 수치는 제외했습니다. 도저히 안됨. 구글트렌드 추이비율 시트에 있음
성환 - 트랜드 지수 컬럼 추가해서 상관관계
유빈-  output_semifinal4 에 트렌드지수 추가해서 output_semifinal5 버전으로 만들어주시면 감사하겠습니다!
성환 - output_semifinal5.csv 파일로 저장했습니다. Trend컬럼에 0.00130단위로 입력완료. 
content/drive/MyDrive/아이펠_오마카세_프로젝트/ brand_names.xlsx 파일에 (카테고리별 Trend그래프 넣어놨습니다. Trend시트에 )

상혁 - 카테고리별 평균값을 기준으로 가격의 높고 낮음에 따라 팔리고 안팔리는것으로 구분
성환 - 만약 안팔린것이 60%로높게 나왔다면 기준을 바꾸는것이 어떨가요? 중고거래사이트 특성상 거래가 이루어 졌을때 이후에 인사이트 도출에 
의미가 있는데 거래자체가 안되었다고 하면 부정적인것 같다.
상혁 - 다시 보니 제대로 되었다 판매거래 된것이 안팔린것보다 60%이상으로 높은 결과였다.
성환 - 그렇다면 긍정적인 결과로 봐도 될거 같습니다.
상혁 - 카테고리별 평균값을 기준으로 가격의 높고 낮음에 따라 팔리고 안팔리는것으로 구분했으나, 미디엄 값으로 하는것이 그래프로 봤을때 
크게 차이가 없어 미디엄값으로 하는것이 어떤지?
성환 - 평균 값을 기준으로 했을때 거래가 많이 이루어 지는 분포인 평균값으로 진행하는걸로 

**분석목표 설정**
거래 성사율 및 수익 극대화를 위한 가격·신뢰도 증가를 위한 비즈니스 전략제안.
1. 거래 성사율 및 수익 극대화
가격 추천을 통해 적정 가격을 제시하여 거래 성사율을 높인다.
플랫폼 수수료(또는 광고 수익)가 늘어나면서 전체 수익이 극대화 된다.
2. 사용자 신뢰도 제고
프리미엄 판매자 제도(설명 품질·긍정 리뷰·판매 이력 등)를 도입, 신뢰도 높은 판매자와 상품을 상단 노출 → 구매 전환율 상승.
카테고리별 평균 거래가, 부정·긍정 키워드 분석 등을 통해 구매자가 안심하고 거래할 수 있도록 지원.
3. 트렌드별 인사이트 제공
인기 상품과 가격 변동 추이를 파악 → 판매자에게 맞춤형 가격 전략 및 마케팅 제안.
인기 브랜드 지표(검색량 증가율(클릭수) 등)로 구매자 이목을 끌고, 판매자는 효율적인 재고·상품 등록 전략 수립 가능.
4. 장기적 경쟁력 강화
지속적인 동적 가격 최적화가 가능.
사용자에게 일관되게 높은 신뢰를 주어 고객 충성도를 확보하고, 타 플랫폼과의 차별화.

3일차 야근작업내용
상혁 - 만일 price부분만 0이고 나머지가 전부 최댓값이라면 가중치가 적용되었을 때 0.4*0 + 0.25*1 + 0.15*1 + 0.1*1 + 0.1*1
= 판매 가능성 60프로로 나타날 것입니다. 종합하여 판매 가능성 보여지는 column 만들어보겠습니다.
유빈 - 가격/배송 상관관계의 상관관계가 높게 나온 카테고리는 handmade 제품이 多 
상혁 - 그부분은 무시해도 될듯 
유빈 - shipping 넣으면 안될까요? 카테고리명 반영된 것같은데
상혁 - 그래프가 있긴한데 그거 카테고리가 거의 소분류 기준으로 잡혔고, 상관관계가 양수인것은 서로 비례관계라는건데
이게 일관성 여부에 있어서 너무 분류가 소분류 그리고 그 그래프 전에 상관관계 분석들 보면 다 -라서 -인 상관관계가 더 많아요
그래프로 좀 그려졌으면 좋겠다 싶은걸 요구해 주세요.
상혁 - 성환님 Trand 값이 너무 작아서 최댓값이 0.00412 더라고요. 그래서 Trand 값 전체를 *1000 으로 진행해서
가중치에 진행하고자 하는데 어떠신지 여쭈어봅니다
성환 - Trend 현재 있는 값에 무조건 100곱하면 됩니다. # Trend 컬럼의 값을 100배로 변환 
df_trend['Trend'] = df_trend['Trend'] * 100

4일차(2/27) (03:00)
유빈 - 각자 PPT파일에 본인이 담당했던 내용 페이지 채워주시면됩니다.성환님 트렌드 지수 높은 카테고리 10개랑, 
낮은 카테고리 10개 리스트 뽑아서 리스트와 트렌드 지수 있는걸로 요청 
상혁 - 판매 예상율 데이터 분석을 발표자료에 공유함.
(12:50 발표자료 PPT 9차까지 수정진행 되어 최종본 공유함)
